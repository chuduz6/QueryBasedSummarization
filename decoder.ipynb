{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import logging\n",
    "import json\n",
    "import io\n",
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# this loop is needed to reset the flags to that notebook won't throw duplicate flags error\n",
    "from absl import flags\n",
    "for name in list(flags.FLAGS):\n",
    "  delattr(flags.FLAGS, name)\n",
    "\n",
    "# Dictionary parameters\n",
    "tf.app.flags.DEFINE_string(\"doc_dict_path\", \"doc_dict.txt\", \"Document Dictionary output.\")\n",
    "tf.app.flags.DEFINE_string(\"sum_dict_path\", \"sum_dict.txt\", \"Summary Dictionary output.\")\n",
    "tf.app.flags.DEFINE_boolean(\"create_dict_flag\", False, \"Whether to create new dictionary or not \")\n",
    "tf.app.flags.DEFINE_integer(\"doc_vocab_size\", 30000, \"Document vocabulary size.\")\n",
    "tf.app.flags.DEFINE_integer(\"sum_vocab_size\", 10000, \"Summary vocabulary size.\")\n",
    "tf.app.flags.DEFINE_float(\"train_test_split\", 0.33, \"Test Split ratio\")\n",
    "tf.app.flags.DEFINE_boolean(\"pretrained_embeddings\", True, \"Whether to look up pre-trained embedding for not \")\n",
    "tf.app.flags.DEFINE_string(\"embedding_path\", \"glove.twitter.27B.100d.txt\", \"Embedding path\")\n",
    "\n",
    "\n",
    "# needed to get rid of missing f parameter\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "# Optimization Parameters\n",
    "tf.app.flags.DEFINE_float(\"learning_rate\", 0.1, \"Learning rate.\")\n",
    "tf.app.flags.DEFINE_integer(\"size\", 400, \"Size of hidden layers.\")\n",
    "tf.app.flags.DEFINE_integer(\"embsize\", 100, \"Size of embedding.\")\n",
    "tf.app.flags.DEFINE_integer(\"num_layers\", 1, \"Number of layers in the model.\")\n",
    "tf.app.flags.DEFINE_float(\"max_gradient\", 1.0, \"Clip gradients l2 norm to this range.\")\n",
    "tf.app.flags.DEFINE_integer(\"batch_size\", 5, \"Batch size\")\n",
    "tf.app.flags.DEFINE_integer(\"beam_width_size\", 1, \"beam size\")\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\"max_epochs\", 1, \"Maximum training Epochs.\")\n",
    "tf.app.flags.DEFINE_float(\"doc_encoder_keep_prob\", 0.5, \"doc keep prob\")\n",
    "tf.app.flags.DEFINE_float(\"query_encoder_keep_prob\", 0.5, \"query keep prob\")\n",
    "tf.app.flags.DEFINE_float(\"decoder_keep_prob\", 0.5, \"decoder keep prob\")\n",
    "\n",
    "\n",
    "tf.app.flags.DEFINE_boolean(\"doc_encoder_dropout_flag\", True, \"Whether to drop out doc encoder cell\")\n",
    "tf.app.flags.DEFINE_boolean(\"query_encoder_dropout_flag\", True, \"Whether to drop out query encoder cell\")\n",
    "tf.app.flags.DEFINE_boolean(\"decoder_dropout_flag\", True, \"Whether to drop out query encoder cell\")\n",
    "\n",
    "\n",
    "# Data Directory Paramters\n",
    "tf.app.flags.DEFINE_string(\"data_dir\", \"data_sample_train.json\", \"Data directory\")\n",
    "tf.app.flags.DEFINE_string(\"test_file\", \"data_sample_test.txt\", \"Test filename.\")\n",
    "\n",
    "# Output Data Directory Parameters\n",
    "tf.app.flags.DEFINE_string(\"test_output\", \"test_output.txt\", \"Test output.\")\n",
    "tf.app.flags.DEFINE_string(\"train_dir\", \"model\", \"Training directory.\")\n",
    "tf.app.flags.DEFINE_string(\"tfboard\", \"tfboard\", \"Tensorboard log directory.\")\n",
    "tf.app.flags.DEFINE_integer(\"steps_per_print\", 50, \"Training steps between printing.\")\n",
    "tf.app.flags.DEFINE_integer(\"steps_per_validation\", 1000, \"Training steps between validations.\")\n",
    "tf.app.flags.DEFINE_integer(\"steps_per_checkpoint\", 750, \"Training steps between checkpoints.\")\n",
    "tf.app.flags.DEFINE_boolean(\"load_checkpoint\", False, \"Flag to whether load the checkpoint or not\")\n",
    "\n",
    "\n",
    "# Progam Running Mode: Train or decode\n",
    "tf.app.flags.DEFINE_boolean(\"decode\", False, \"Set to True for testing.\")\n",
    "tf.app.flags.DEFINE_boolean(\"geneos\", True, \"Do not generate EOS. \")\n",
    "\n",
    "tf.app.flags.DEFINE_integer('seed',           3435, 'random number generator seed')\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "    \n",
    "logging.basicConfig(level=logging.INFO,format=\"%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s\",datefmt='%b %d %H:%M')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARK_PAD = \"<PAD>\"\n",
    "MARK_UNK = \"<UNK>\"\n",
    "MARK_EOS = \"<EOS>\"\n",
    "MARK_GO = \"<GO>\"\n",
    "MARKS = [MARK_PAD, MARK_UNK, MARK_EOS, MARK_GO]\n",
    "ID_PAD = 0\n",
    "ID_UNK = 1\n",
    "ID_EOS = 2\n",
    "ID_GO = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(dict_path, max_vocab=None):\n",
    "    logging.info(\"Try load dict from {}.\".format(dict_path))\n",
    "    try:\n",
    "        dict_file = open(dict_path)\n",
    "        dict_data = dict_file.readlines()\n",
    "        dict_file.close()\n",
    "    except:\n",
    "        logging.info(\"Load dict {dict} failed, create later.\".format(dict=dict_path))\n",
    "        return None\n",
    "\n",
    "    dict_data = list(map(lambda x: x.split(), dict_data))\n",
    "    if max_vocab:\n",
    "        dict_data = list(filter(lambda x: int(x[0]) < max_vocab, dict_data))\n",
    "    tok2id = dict(map(lambda x: (x[1], int(x[0])), dict_data))\n",
    "    id2tok = dict(map(lambda x: (int(x[0]), x[1]), dict_data))\n",
    "    logging.info(\"Load dict {} with {} words.\".format(dict_path, len(tok2id)))\n",
    "    return (tok2id, id2tok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(dict_path, corpus, max_vocab=None):\n",
    "    logging.info(\"Create dict {}.\".format(dict_path))\n",
    "    counter = {}\n",
    "    counter2 = 0\n",
    "    for line in corpus:\n",
    "        for word in line:\n",
    "            try:\n",
    "                counter[word] += 1\n",
    "            except:\n",
    "                counter[word] = 1\n",
    "\n",
    "    for mark_t in MARKS:\n",
    "        if mark_t in counter:\n",
    "            del counter[mark_t]\n",
    "            logging.warning(\"{} appears in corpus.\".format(mark_t))\n",
    "\n",
    "    counter = list(counter.items())\n",
    "    counter.sort(key=lambda x: -x[1])\n",
    "    words = list(map(lambda x: x[0], counter))\n",
    "    words = [MARK_PAD, MARK_UNK, MARK_EOS, MARK_GO] + words\n",
    "    if max_vocab:\n",
    "        words = words[:max_vocab]\n",
    "\n",
    "    tok2id = dict()\n",
    "    id2tok = dict()\n",
    "    with open(dict_path, 'w') as dict_file:\n",
    "        for idx, tok in enumerate(words):\n",
    "            print(idx, tok, file=dict_file)\n",
    "            tok2id[tok] = idx\n",
    "            id2tok[idx] = tok\n",
    "\n",
    "    logging.info(\"Create dict {} with {} words.\".format(dict_path, len(words)))\n",
    "    return (tok2id, id2tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_map2id(data, tok2id):\n",
    "    ret = []\n",
    "    unk = 0\n",
    "    tot = 0\n",
    "    for doc in data:\n",
    "        tmp = []\n",
    "        for word in doc:\n",
    "            tot += 1\n",
    "            try:\n",
    "                tmp.append(tok2id[word])\n",
    "            except:\n",
    "                tmp.append(ID_UNK)\n",
    "                unk +=1\n",
    "        ret.append(tmp)\n",
    "    print (\"TOTAL :\", tot, \" UNK :\", unk)\n",
    "    return ret, (tot - unk)/tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sen_map2tok(sen, id2tok):\n",
    "\treturn list(map(lambda x: id2tok[x], sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep 10 13:05 <ipython-input-9-c23af9b8db75>[line:2] INFO Load document from data_sample_train.json.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logging.info(\"Load document from {}.\".format(FLAGS.data_dir))\n",
    "with io.open(FLAGS.data_dir, 'r', encoding='ascii', errors='ignore') as input_file:\n",
    "    data = json.loads(input_file.read())\n",
    "    docs = []\n",
    "    summaries = []\n",
    "    queries = []\n",
    "    for i in range (len(data['passages'])):\n",
    "        docs.append(' '.join([data['passages'][str(i)][j]['passage_text'] for j in range (len(data['passages'][str(i)]))]))\n",
    "        summaries.append(''.join(data['answers'][str(i)]))\n",
    "        queries.append(data['query'][str(i)])\n",
    "\n",
    "assert \tlen(docs) == len(queries)\n",
    "print (len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY : . what is a corporation?\n",
      "ANSWER : A corporation is a company or group of people authorized to act as a single entity and recognized as such in law.\n"
     ]
    }
   ],
   "source": [
    "#print (\"DOCS :\", docs[0])\n",
    "print (\"QUERY :\", queries[0])\n",
    "print (\"ANSWER :\", summaries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting docs...\n",
      "TIME TAKEN TO SPLIT DOCS:  0.08885884284973145\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:1'):\n",
    "    print (\"Splitting docs...\")\n",
    "\n",
    "    #print (\"BEFORE SPLITTING: \", docs[0])\n",
    "    now = time.time()\n",
    "    docs_splitted = list(map(lambda x: word_tokenize(x), docs))\n",
    "    docs_splitted = [[word.lower()for word in doc] for doc in docs_splitted]\n",
    "    del docs\n",
    "    print (\"TIME TAKEN TO SPLIT DOCS: \", time.time()-now)\n",
    "    #print (\"AFTER SPLITTING: \", docs[0])\n",
    "    print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting queries...\n",
      "DONE\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "print (\"Splitting queries...\")\n",
    "queries_splitted = list(map(lambda x: [y.lower() for y in word_tokenize(x)], queries)) \n",
    "del queries\n",
    "print (\"DONE\")\n",
    "print (len(queries_splitted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting summaries...\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print (\"Splitting summaries...\")\n",
    "summaries_splitted = list(map(lambda x: [y.lower() for y in word_tokenize(x)], summaries)) \n",
    "del summaries\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep 10 13:05 <ipython-input-5-680d20c1ecef>[line:2] INFO Try load dict from doc_dict.txt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on dictionary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep 10 13:05 <ipython-input-5-680d20c1ecef>[line:16] INFO Load dict doc_dict.txt with 30000 words.\n",
      "Sep 10 13:05 <ipython-input-5-680d20c1ecef>[line:2] INFO Try load dict from sum_dict.txt.\n",
      "Sep 10 13:05 <ipython-input-5-680d20c1ecef>[line:16] INFO Load dict sum_dict.txt with 10000 words.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print (\"Working on dictionary...\")\n",
    "if(FLAGS.create_dict_flag):\n",
    "    doc_dict = create_dict(FLAGS.doc_dict_path, docs_splitted+queries_splitted, FLAGS.doc_vocab_size)\n",
    "    sum_dict = create_dict(FLAGS.sum_dict_path, summaries_splitted, FLAGS.sum_vocab_size)\n",
    "else:\n",
    "    doc_dict = load_dict(FLAGS.doc_dict_path, FLAGS.doc_vocab_size)\n",
    "    sum_dict = load_dict(FLAGS.sum_dict_path, FLAGS.sum_vocab_size)\n",
    "\n",
    "print (\"DONE\")\n",
    "print (len(doc_dict))\n",
    "print (len(sum_dict))\n",
    "#print (sum_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep 10 13:05 <ipython-input-15-6f91af374cc1>[line:3] INFO Doc dict covers 97.45% words.\n",
      "Sep 10 13:05 <ipython-input-15-6f91af374cc1>[line:6] INFO Sum dict covers 95.06% words.\n",
      "Sep 10 13:05 <ipython-input-15-6f91af374cc1>[line:9] INFO Query dict covers 99.32% words.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to ids...\n",
      "TOTAL : 12869  UNK : 328\n",
      "TOTAL : 789  UNK : 39\n",
      "TOTAL : 148  UNK : 1\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print (\"Converting to ids...\")\n",
    "docid, cover = corpus_map2id(docs_splitted, doc_dict[0])\n",
    "logging.info(\"Doc dict covers {:.2f}% words.\".format(cover * 100))\n",
    "\n",
    "sumid, cover = corpus_map2id(summaries_splitted, sum_dict[0])\n",
    "logging.info(\"Sum dict covers {:.2f}% words.\".format(cover * 100))\n",
    "\n",
    "queryid, cover = corpus_map2id(queries_splitted, doc_dict[0])\n",
    "logging.info(\"Query dict covers {:.2f}% words.\".format(cover * 100))\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[5, 37, 11, 8, 1557, 63]\n",
      ". what is a corporation ?\n"
     ]
    }
   ],
   "source": [
    "print (len(queryid[0]))\n",
    "print (queryid[0])\n",
    "print (\" \".join(sen_map2tok(queryid[0], doc_dict[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Sep 10 13:05 textcleaner.py[line:37] INFO 'pattern' package not found; tag filters are not available for English\n",
      "Sep 10 13:05 dictionary.py[line:195] INFO adding document #0 to Dictionary(0 unique tokens: [])\n",
      "Sep 10 13:05 dictionary.py[line:202] INFO built Dictionary(12 unique tokens: ['survey', 'trees', 'graph', 'user', 'computer']...) from 9 documents (total 29 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "def get_word_vectors():\n",
    "    glove_file = FLAGS.embedding_path\n",
    "    word2vec_file = get_tmpfile(\"word2vec_format.vec\")\n",
    "    glove2word2vec(glove_file, word2vec_file)\n",
    "    print(\"Loading Glove vectors...\")\n",
    "    word_vectors = KeyedVectors.load_word2vec_format(word2vec_file)\n",
    "    return word_vectors\n",
    "#word_vectors = get_word_vectors()\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "'''\n",
    "with open('word_vectors.pickle', 'wb') as handle:\n",
    "    pickle.dump(word_vectors, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "'''\n",
    "with open('word_vectors.pickle', 'rb') as handle:\n",
    "    word_vectors = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "def get_init_embedding(word_vectors, word_vocab, vocab_size):\n",
    "    word_vec_list = list()\n",
    "    success_count = 0\n",
    "    failure_count = 0\n",
    "    for word, _ in word_vocab[0].items():\n",
    "        try:\n",
    "            word_vec = word_vectors.word_vec(word)\n",
    "            success_count += 1\n",
    "        except KeyError:\n",
    "            word_vec = np.zeros([FLAGS.embsize], dtype=np.float32)\n",
    "            failure_count += 1\n",
    "        word_vec_list.append(word_vec)\n",
    "\n",
    "    word_vec_list[2] = np.random.normal(0, 1, FLAGS.embsize)\n",
    "    word_vec_list[3] = np.random.normal(0, 1, FLAGS.embsize)\n",
    "    print (\"SUCCESS COUNT: \", success_count, \" FAILURE COUNT: \", failure_count)\n",
    "    return np.array(word_vec_list)\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS COUNT:  25251  FAILURE COUNT:  4749\n",
      "SUCCESS COUNT:  9505  FAILURE COUNT:  495\n",
      "LOADED GLOVE VECTORS IN TIME:  0.23436522483825684\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "if FLAGS.pretrained_embeddings:\n",
    "    init_embeddings_doc = tf.constant(get_init_embedding(word_vectors, doc_dict, FLAGS.doc_vocab_size), dtype=tf.float32)\n",
    "    init_embeddings_sum = tf.constant(get_init_embedding(word_vectors, sum_dict, FLAGS.sum_vocab_size), dtype=tf.float32)\n",
    "print (\"LOADED GLOVE VECTORS IN TIME: \", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer = tf.contrib.layers.fully_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "class BiGRUModel(object):\n",
    "\n",
    "    def __init__(self,doc_dict, sum_dict, source_vocab_size,target_vocab_size, buckets, state_size, num_layers, embedding_size, max_gradient, batch_size, learning_rate, forward_only=False, beam_width=1, dtype=tf.float32):\n",
    "\n",
    "        self.source_vocab_size = source_vocab_size\n",
    "        self.target_vocab_size = target_vocab_size\n",
    "        self.buckets = buckets\n",
    "        self.batch_size = batch_size\n",
    "        self.beam_width = beam_width\n",
    "        self.learning_rate = learning_rate\n",
    "        self.global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "        self.state_size = state_size\n",
    "        self.sum_dict = sum_dict\n",
    "        self.doc_dict = doc_dict\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.encoder_query_inputs = tf.placeholder( tf.int32, shape=[self.batch_size, None], name='qI')\n",
    "        self.encoder_doc_inputs = tf.placeholder( tf.int32, shape=[self.batch_size, None], name='docI')\n",
    "        self.decoder_inputs = tf.placeholder(tf.int32, shape=[self.batch_size, None], name='decI')\n",
    "        self.decoder_targets = tf.placeholder(tf.int32, shape=[self.batch_size, None], name='decT')\n",
    "        self.encoder_query_len = tf.placeholder(tf.int32, shape=[self.batch_size], name='qL')\n",
    "        self.encoder_doc_len = tf.placeholder(tf.int32, shape=[self.batch_size], name='docL')\n",
    "        self.decoder_len = tf.placeholder(tf.int32, shape=[self.batch_size], name='decL')\n",
    "\n",
    "\n",
    "        with tf.variable_scope(\"seq2seq\", dtype=dtype):\n",
    "            \n",
    "            with tf.variable_scope(\"decoder/projection\"):\n",
    "                self.projection_layer = tf.layers.Dense(self.target_vocab_size, use_bias=False)\n",
    "                \n",
    "            \n",
    "            with tf.variable_scope(\"embedding\"):                \n",
    "                if not forward_only and FLAGS.pretrained_embeddings is not None:\n",
    "                    init_embeddings_doc = tf.constant(get_init_embedding(word_vectors, doc_dict, FLAGS.doc_vocab_size), dtype=tf.float32)\n",
    "                    init_embeddings_sum = tf.constant(get_init_embedding(word_vectors, sum_dict, FLAGS.sum_vocab_size), dtype=tf.float32)\n",
    "                else:\n",
    "                    init_embeddings_doc = tf.random_uniform([self.source_vocab_size, self.embedding_size], -1.0, 1.0)\n",
    "                    init_embeddings_sum = tf.random_uniform([self.target_vocab_size, self.embedding_size], -1.0, 1.0)                \n",
    "                encoder_query_emb = tf.get_variable(\"embedding_query\", initializer=init_embeddings_doc)\n",
    "                encoder_doc_emb = tf.get_variable(\"embedding_doc\", initializer=init_embeddings_doc)\n",
    "                decoder_emb = tf.get_variable(\"embedding\", initializer= init_embeddings_sum)\n",
    "                encoder_query_inputs_emb = tf.nn.embedding_lookup(encoder_query_emb, self.encoder_query_inputs)\n",
    "                encoder_doc_inputs_emb = tf.nn.embedding_lookup(encoder_doc_emb, self.encoder_doc_inputs)\n",
    "                decoder_inputs_emb = tf.nn.embedding_lookup(decoder_emb, self.decoder_inputs)\n",
    "\n",
    "                \n",
    "            with tf.variable_scope(\"encoder_query\"):                                   \n",
    "                encoder_fw_cells_query = [tf.contrib.rnn.GRUCell(state_size) for _ in range(FLAGS.num_layers)]\n",
    "                encoder_bw_cells_query = [tf.contrib.rnn.GRUCell(state_size) for _ in range(FLAGS.num_layers)]\n",
    "                if(FLAGS.query_encoder_dropout_flag):\n",
    "                    if not forward_only:\n",
    "                        encoder_fw_cells_query = [tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=FLAGS.query_encoder_keep_prob) for cell in encoder_fw_cells_query]\n",
    "                        encoder_bw_cells_query = [tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=FLAGS.query_encoder_keep_prob) for cell in encoder_bw_cells_query]\n",
    "                encoder_query_outputs, encoder_query_states_fw, encoder_query_states_bw = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(encoder_fw_cells_query, encoder_bw_cells_query, encoder_query_inputs_emb, sequence_length=self.encoder_query_len, dtype=dtype)\n",
    "                if(self.batch_size != 1):\n",
    "                    encoder_query_states = tf.squeeze(tf.convert_to_tensor(encoder_query_states_fw)), tf.squeeze(tf.convert_to_tensor(encoder_query_states_bw))\n",
    "                else:\n",
    "                    encoder_query_states = tf.reshape(tf.squeeze(encoder_query_states_fw), [1, -1]), tf.reshape(tf.squeeze(encoder_query_states_bw), [1, -1])                    \n",
    "                    \n",
    "                print (\"ENCODER QUERY STATES: \", encoder_query_states)\n",
    "\n",
    "            with tf.variable_scope(\"encoder_doc\"):                \n",
    "                encoder_fw_cells_doc = [tf.contrib.rnn.GRUCell(state_size) for _ in range(FLAGS.num_layers)]\n",
    "                encoder_bw_cells_doc = [tf.contrib.rnn.GRUCell(state_size) for _ in range(FLAGS.num_layers)]\n",
    "                if(FLAGS.doc_encoder_dropout_flag):\n",
    "                    if not forward_only:\n",
    "                        encoder_fw_cells_doc = [tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=FLAGS.doc_encoder_keep_prob) for cell in encoder_fw_cells_doc]\n",
    "                        encoder_bw_cells_doc = [tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=FLAGS.doc_encoder_keep_prob) for cell in encoder_bw_cells_doc]\n",
    "                encoder_doc_outputs, encoder_doc_states_fw, encoder_doc_states_bw = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(encoder_fw_cells_doc, encoder_bw_cells_doc, encoder_doc_inputs_emb, sequence_length=self.encoder_doc_len, dtype=dtype)\n",
    "                if(self.batch_size != 1):\n",
    "                    encoder_doc_states = tf.squeeze(tf.convert_to_tensor(encoder_doc_states_fw)), tf.squeeze(tf.convert_to_tensor(encoder_doc_states_bw))\n",
    "                else:\n",
    "                    encoder_doc_states = tf.reshape(tf.squeeze(encoder_doc_states_fw), [1, -1]), tf.reshape(tf.squeeze(encoder_doc_states_bw), [1, -1])                    \n",
    "                    \n",
    "                print (\"ENCODER DOC STATES: \", encoder_doc_states)\n",
    "                \n",
    "                    \n",
    "            with tf.name_scope(\"decoder\"), tf.variable_scope(\"decoder\") as decoder_scope:       \n",
    "                decoder_cell = tf.contrib.rnn.GRUCell(state_size)\n",
    "                if(FLAGS.decoder_dropout_flag):\n",
    "                    if not forward_only:\n",
    "                        decoder_cell = tf.contrib.rnn.DropoutWrapper(decoder_cell, output_keep_prob=FLAGS.decoder_keep_prob)                \n",
    "                \n",
    "                if not forward_only:\n",
    "                    init_state_query = fc_layer(tf.concat(encoder_query_states, 1), state_size)\n",
    "                    print (\"INIT STATE QUERY: \", init_state_query)\n",
    "                    self.init_state_query = init_state_query\n",
    "                    self.init_state_query.set_shape([self.batch_size, state_size])\n",
    "                    self.att_states_query = tf.concat(encoder_query_outputs, 2)\n",
    "                    self.att_states_query.set_shape([self.batch_size, None, state_size*2])\n",
    "\n",
    "                    init_state_doc = fc_layer( tf.concat(encoder_doc_states, 1), state_size)\n",
    "                    self.init_state_doc = init_state_doc\n",
    "                    self.init_state_doc.set_shape([self.batch_size, state_size])\n",
    "                    self.att_states_doc = tf.concat(encoder_doc_outputs, 2)\n",
    "                    self.att_states_doc.set_shape([self.batch_size, None, state_size*2])\n",
    "\n",
    "                    attention_mechanism_query = tf.contrib.seq2seq.BahdanauAttention(state_size, self.att_states_query, self.encoder_query_len)\n",
    "                    attention_state_query = tf.contrib.seq2seq.AttentionWrapper(decoder_cell, attention_mechanism_query, state_size * 2)              \n",
    "\n",
    "                    attention_mechanism_doc = tf.contrib.seq2seq.BahdanauAttention(state_size, self.att_states_doc, self.encoder_doc_len)                \n",
    "                    decoder_cell = tf.contrib.seq2seq.AttentionWrapper(attention_state_query, attention_mechanism_doc, state_size * 2)               \n",
    "\n",
    "                    combined_final_states = fc_layer(tf.concat((self.init_state_query, self.init_state_doc), 1), state_size)\n",
    "                    print (\"COMBINED FINAL STATES: \", combined_final_states)\n",
    "                    decoder_cell_zero = decoder_cell.zero_state(dtype=tf.float32, batch_size=self.batch_size)\n",
    "                    initial_state = decoder_cell_zero\n",
    "\n",
    "                    decoder_cell = tf.contrib.rnn.OutputProjectionWrapper(decoder_cell, target_vocab_size)\n",
    "                    helper = tf.contrib.seq2seq.TrainingHelper(decoder_inputs_emb, self.decoder_len)\n",
    "                    decoder = tf.contrib.seq2seq.BasicDecoder(cell=decoder_cell, helper=helper, initial_state=initial_state)\n",
    "                    outputs = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
    "                    outputs_logits = outputs[0].rnn_output\n",
    "                    self.outputs = outputs_logits      \n",
    "\n",
    "                else:\n",
    "                    init_state_query = fc_layer(tf.concat(encoder_query_states, 1), state_size)\n",
    "                    print (\"INIT STATE QUERY: \", init_state_query)\n",
    "                    self.init_state_query = init_state_query\n",
    "                    self.init_state_query.set_shape([self.batch_size, state_size])\n",
    "                    self.att_states_query = tf.concat(encoder_query_outputs, 2)\n",
    "                    self.att_states_query.set_shape([self.batch_size, None, state_size*2])\n",
    "                    self.att_states_query = tf.contrib.seq2seq.tile_batch(self.att_states_query, multiplier=self.beam_width)\n",
    "                    self.encoder_query_len = tf.contrib.seq2seq.tile_batch(self.encoder_query_len, multiplier=self.beam_width)\n",
    "\n",
    "\n",
    "                    init_state_doc = fc_layer( tf.concat(encoder_doc_states, 1), state_size)\n",
    "                    self.init_state_doc = init_state_doc\n",
    "                    self.init_state_doc.set_shape([self.batch_size, state_size])\n",
    "                    self.att_states_doc = tf.concat(encoder_doc_outputs, 2)\n",
    "                    self.att_states_doc.set_shape([self.batch_size, None, state_size*2])\n",
    "                    self.att_states_doc = tf.contrib.seq2seq.tile_batch(self.att_states_doc, multiplier=self.beam_width)\n",
    "                    self.encoder_doc_len= tf.contrib.seq2seq.tile_batch(self.encoder_doc_len, multiplier=self.beam_width)\n",
    "\n",
    "\n",
    "                    attention_mechanism_query = tf.contrib.seq2seq.BahdanauAttention(state_size, self.att_states_query, self.encoder_query_len)\n",
    "                    attention_state_query = tf.contrib.seq2seq.AttentionWrapper(decoder_cell, attention_mechanism_query, state_size * 2)              \n",
    "\n",
    "                    attention_mechanism_doc = tf.contrib.seq2seq.BahdanauAttention(state_size, self.att_states_doc, self.encoder_doc_len)                \n",
    "                    decoder_cell = tf.contrib.seq2seq.AttentionWrapper(attention_state_query, attention_mechanism_doc, state_size * 2)               \n",
    "\n",
    "                    combined_final_states = fc_layer(tf.concat((self.init_state_query, self.init_state_doc), 1), state_size)\n",
    "                    print (\"COMBINED FINAL STATES BEFORE: \", combined_final_states)\n",
    "                    combined_final_states = tf.contrib.seq2seq.tile_batch(combined_final_states, multiplier=self.beam_width)\n",
    "                    print (\"COMBINED FINAL STATES: \", combined_final_states)\n",
    "                    decoder_cell_zero = decoder_cell.zero_state(dtype=tf.float32, batch_size=batch_size*self.beam_width)\n",
    "                    initial_state = decoder_cell_zero\n",
    "\n",
    "\n",
    "                    decoder_cell = tf.contrib.rnn.OutputProjectionWrapper(decoder_cell, target_vocab_size)\n",
    "\n",
    "\n",
    "                    decoder = tf.contrib.seq2seq.BeamSearchDecoder(cell=decoder_cell,\n",
    "                                                               embedding=decoder_emb,\n",
    "                                                               start_tokens=tf.fill([self.batch_size], tf.constant(ID_GO)),\n",
    "                                                               end_token=tf.constant(ID_EOS), \n",
    "                                                               initial_state=initial_state,\n",
    "                                                               beam_width=self.beam_width,\n",
    "                                                               output_layer=None)\n",
    "                    print (\"DECODER: \", decoder)\n",
    "                    outputs = tf.contrib.seq2seq.dynamic_decode(decoder, maximum_iterations=50)\n",
    "                    self.predictions = outputs[1]\n",
    "\n",
    "                \n",
    "            with tf.variable_scope(\"loss\"):\n",
    "                if not forward_only:\n",
    "                    #print (\"SHAPE OF OUTPUTS: \", tf.shape(outputs_logits, out_type=tf.int32 ))\n",
    "                    #print (\"SHAPE OF TARGETS: \", tf.shape(self.decoder_targets, out_type=tf.int32))\n",
    "                    weights = tf.sequence_mask(self.decoder_len, dtype=tf.float32)\n",
    "                    loss_t = tf.contrib.seq2seq.sequence_loss(outputs_logits, self.decoder_targets, weights, average_across_timesteps=False, average_across_batch=False)\n",
    "                    self.loss = tf.reduce_sum(loss_t)/FLAGS.batch_size\n",
    "\n",
    "\n",
    "\n",
    "                    predictions = tf.cast(tf.argmax(outputs_logits, axis=2), tf.int32) \n",
    "                    self.accuracy = tf.contrib.metrics.accuracy(predictions, self.decoder_targets)\n",
    "\n",
    "\n",
    "\n",
    "                    params = tf.trainable_variables()\n",
    "                    opt = tf.train.AdadeltaOptimizer(self.learning_rate, epsilon=1e-4)\n",
    "                    gradients = tf.gradients(self.loss, params)\n",
    "                    clipped_gradients, norm = \\\n",
    "                        tf.clip_by_global_norm(gradients, max_gradient)\n",
    "                    self.updates = opt.apply_gradients(zip(clipped_gradients, params), global_step=self.global_step)\n",
    "                    tf.summary.scalar('loss', self.loss)\n",
    "                    tf.summary.scalar('accuracy', self.accuracy)\n",
    "\n",
    "        \n",
    "        self.saver = tf.train.Saver(max_to_keep=20)\n",
    "        self.summary_merge = tf.summary.merge_all()    \n",
    "\n",
    "    \n",
    "    def step(self,session,encoder_doc_inputs,encoder_query_inputs,decoder_inputs,encoder_doc_len,encoder_query_len,decoder_len,forward_only,summary_writer=None):\n",
    "\n",
    "        # dim fit is important for sequence_mask\n",
    "        # TODO better way to use sequence_mask\n",
    "        if encoder_query_inputs.shape[1] != max(encoder_query_len):\n",
    "            raise ValueError(\"encoder_query_inputs and encoder_query_len does not fit\")\n",
    "        if encoder_doc_inputs.shape[1] != max(encoder_doc_len):\n",
    "            raise ValueError(\"encoder_doc_inputs and encoder_doc_len does not fit\")\n",
    "        if not forward_only and \\\n",
    "            decoder_inputs.shape[1] != max(decoder_len) + 1:\n",
    "            raise ValueError(\"decoder_inputs and decoder_len does not fit\")\n",
    "            \n",
    "        input_feed = {}\n",
    "        input_feed[self.encoder_query_inputs] = encoder_query_inputs\n",
    "        input_feed[self.encoder_doc_inputs] = encoder_doc_inputs\n",
    "        input_feed[self.decoder_inputs] = decoder_inputs[:, :-1]\n",
    "        input_feed[self.decoder_targets] = decoder_inputs[:, 1:]\n",
    "        input_feed[self.encoder_query_len] = encoder_query_len\n",
    "        input_feed[self.encoder_doc_len] = encoder_doc_len\n",
    "        input_feed[self.decoder_len] = decoder_len\n",
    "\n",
    "        output_feed = [self.loss, self.accuracy, self.updates]\n",
    "        \n",
    "        if summary_writer:\n",
    "            output_feed += [self.summary_merge, self.global_step]\n",
    "\n",
    "        outputs = session.run(output_feed, input_feed)\n",
    "\n",
    "        if summary_writer:\n",
    "            summary_writer.add_summary(outputs[3], outputs[4])\n",
    "        return outputs[:3]\n",
    "    \n",
    "\n",
    "    def step_beam(self, session, encoder_doc_inputs, encoder_query_inputs, encoder_doc_len, encoder_query_len, beam_size):\n",
    "        \n",
    "        if encoder_doc_inputs.shape[0] == 1:\n",
    "            print (\" CAME TO INPUT SHAPE:\")\n",
    "            encoder_doc_inputs = np.repeat(encoder_doc_inputs, beam_size, axis=0)\n",
    "            encoder_doc_len = np.repeat(encoder_doc_len, beam_size, axis=0)      \n",
    "        \n",
    "        if encoder_query_inputs.shape[0] == 1:\n",
    "            print (\" CAME TO INPUT SHAPE:\")\n",
    "            encoder_query_inputs = np.repeat(encoder_query_inputs, beam_size, axis=0)\n",
    "            encoder_query_len = np.repeat(encoder_query_len, beam_size, axis=0)    \n",
    "        print (\"ENCODER QUERY SHAPE: \", session.run(tf.shape(encoder_query_len)) )  \n",
    "        \n",
    "        input_feed = {}\n",
    "        input_feed[self.encoder_query_inputs] = encoder_query_inputs\n",
    "        input_feed[self.encoder_doc_inputs] = encoder_doc_inputs\n",
    "        input_feed[self.encoder_query_len] = encoder_query_len\n",
    "        input_feed[self.encoder_doc_len] = encoder_doc_len\n",
    "        \n",
    "        output_feed = [self.predictions]\n",
    "        outputs = session.run(output_feed, input_feed)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "\n",
    "    def add_pad(self, data, fixlen):\n",
    "        data = map(lambda x: x + [ID_PAD] * (fixlen - len(x)), data)\n",
    "        data = list(data)\n",
    "        return np.asarray(data)\n",
    "    \n",
    "    def batchify (self, data_set, _buckets, batch_size):\n",
    "        print (\"BATCH SIZE IS: \", batch_size)\n",
    "        batched_data_set = []\n",
    "        encoder_query_inputs, encoder_doc_inputs, decoder_inputs = [], [], []\n",
    "        encoder_query_len, encoder_doc_len, decoder_len = [], [], []\n",
    "        num_data = 0\n",
    "        counter = 0\n",
    "        for bucket_id in range (len(_buckets)):\n",
    "            if(len(data_set[bucket_id])==0):\n",
    "                continue\n",
    "            for j in range(len(data_set[bucket_id])):\n",
    "                counter += 1\n",
    "                encoder_doc_input, encoder_query_input, decoder_input = data_set[bucket_id][j]\n",
    "                encoder_doc_inputs.append(encoder_doc_input)\n",
    "                encoder_doc_len.append(len(encoder_doc_input))            \n",
    "                encoder_query_inputs.append(encoder_query_input)\n",
    "                encoder_query_len.append(len(encoder_query_input))\n",
    "                decoder_inputs.append(decoder_input)\n",
    "                decoder_len.append(len(decoder_input))\n",
    "                num_data += 1\n",
    "                \n",
    "                if(num_data == batch_size):\n",
    "                    num_data = 0\n",
    "                    batch_enc_doc_len = max(encoder_doc_len)\n",
    "                    batch_enc_query_len = max(encoder_query_len)\n",
    "                    batch_dec_len = max(decoder_len)\n",
    "                    encoder_doc_inputs = self.add_pad(encoder_doc_inputs, batch_enc_doc_len)\n",
    "                    encoder_query_inputs = self.add_pad(encoder_query_inputs, batch_enc_query_len)\n",
    "                    decoder_inputs = self.add_pad(decoder_inputs, batch_dec_len)\n",
    "                    encoder_doc_len = np.asarray(encoder_doc_len)\n",
    "                    encoder_query_len = np.asarray(encoder_query_len)\n",
    "                    decoder_len = np.asarray(decoder_len) - 1\n",
    "                    \n",
    "                    batched_data_set.append([encoder_doc_inputs, encoder_query_inputs, decoder_inputs, encoder_doc_len, encoder_query_len, decoder_len])\n",
    "                    \n",
    "                    encoder_query_inputs, encoder_doc_inputs, decoder_inputs = [], [], []\n",
    "                    encoder_query_len, encoder_doc_len, decoder_len = [], [], []\n",
    "        print (\"BATCHED COUNTER: \", counter)\n",
    "        print (\"BATCHED LENGTH: \", len(batched_data_set))\n",
    "        return batched_data_set\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "print (\"DONE\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# We use a number of buckets for sampling\n",
    "_buckets = [(300,5,15), (300,10,20), (300,15,25), (300,20,40), (300,40,50), (350,5,15), (350,10,20), (350,15,25), (350,20,40), (350,40,50), (450,5,15), (450,10,30), (450,15,50), (450,20,100), (450,40,150), (550,5,15), (550,10,30), (550,15,60), (550,20,100), (550,40,150), (650,5,15), (650,10,30), (650,15,60), (650,20,100), (650,40,150), (750,5,15), (750,10,30), (750,15,60), (750,20,100), (750,40,240), (850,5,15), (850,10,30), (850,15,60), (850,20,100), (850,40,240), (1050,5,15), (1050,10,30), (1050,15,60), (1050,20,100), (1050,40,240), (1500,5,15), (1500,10,30), (1500,15,60), (1500,20,100), (1500,40,300), ]\n",
    "\n",
    "\n",
    "print (\"DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "def create_bucket(source, query, target):\n",
    "    totalDocs = len(source)\n",
    "    print (\"TOTAL DOCS BEFORE BUCKETS: \", totalDocs)\n",
    "    data_set = [[] for _ in _buckets]\n",
    "    for s, q, t in zip(source, query, target):\n",
    "        t = [ID_GO] + t + [ID_EOS]\n",
    "        found = False\n",
    "        for bucket_id, (s_size, q_size, t_size) in enumerate(_buckets):\n",
    "            if len(s) <= s_size and len(q) <= q_size and len(t) <= t_size:\n",
    "                data_set[bucket_id].append([s, q, t])\n",
    "                found = True\n",
    "                break\n",
    "        if(found != True):\n",
    "            print (\"Didn't find bucket for {}, {}, {}\".format(len(s), len(q), len(t)))\n",
    "    return data_set\n",
    "\n",
    "\n",
    "def create_model(session, doc_dict, sum_dict, forward_only):\n",
    "    \"\"\"Create model and initialize or load parameters in session.\"\"\"\n",
    "    dtype = tf.float32\n",
    "    model = BiGRUModel(doc_dict, sum_dict, FLAGS.doc_vocab_size, FLAGS.sum_vocab_size, _buckets, FLAGS.size,  FLAGS.num_layers, FLAGS.embsize, FLAGS.max_gradient,\n",
    "        FLAGS.batch_size,     FLAGS.learning_rate,       forward_only, FLAGS.beam_width_size,       dtype=dtype)\n",
    "    print (\"Loading Checkpoint: \", FLAGS.load_checkpoint)\n",
    "    if (FLAGS.load_checkpoint):        \n",
    "        ckpt = tf.train.latest_checkpoint(FLAGS.train_dir)\n",
    "        if ckpt:\n",
    "            #ckpt = ckpt.model_checkpoint_path\n",
    "            if ckpt and tf.train.checkpoint_exists(ckpt):\n",
    "                logging.info(\"Reading model parameters from %s\" % ckpt)\n",
    "                model.saver.restore(session, ckpt)\n",
    "            else:\n",
    "                logging.error(\"Don't have any checkpoints to load: %s\" % ckpt)\n",
    "    else:\n",
    "        logging.info(\"Created model with fresh parameters.\")\n",
    "        session.run(tf.global_variables_initializer())\n",
    "    return model\n",
    "\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:7] INFO Preparing summarization data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:25] INFO Creating 1 layers of 400 units.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS COUNT:  25251  FAILURE COUNT:  4749\n",
      "SUCCESS COUNT:  9505  FAILURE COUNT:  495\n",
      "WARNING:tensorflow:From c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:430: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep 10 13:05 tf_logging.py[line:125] WARNING From c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:430: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep 10 13:05 tf_logging.py[line:125] WARNING From c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER QUERY STATES:  (<tf.Tensor 'seq2seq/encoder_query/Squeeze:0' shape=(5, 400) dtype=float32>, <tf.Tensor 'seq2seq/encoder_query/Squeeze_1:0' shape=(5, 400) dtype=float32>)\n",
      "ENCODER DOC STATES:  (<tf.Tensor 'seq2seq/encoder_doc/Squeeze:0' shape=(5, 400) dtype=float32>, <tf.Tensor 'seq2seq/encoder_doc/Squeeze_1:0' shape=(5, 400) dtype=float32>)\n",
      "INIT STATE QUERY:  Tensor(\"seq2seq/decoder/decoder/fully_connected/Relu:0\", shape=(5, 400), dtype=float32)\n",
      "COMBINED FINAL STATES:  Tensor(\"seq2seq/decoder/decoder/fully_connected_2/Relu:0\", shape=(5, 400), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep 10 13:05 <ipython-input-25-e3aabcbf552f>[line:34] INFO Created model with fresh parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Checkpoint:  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:30] INFO Create buckets.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (300, 5, 15) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (300, 10, 20) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (300, 15, 25) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (300, 20, 40) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (300, 40, 50) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (350, 5, 15) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (350, 10, 20) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (350, 15, 25) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (350, 20, 40) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (350, 40, 50) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (450, 5, 15) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (450, 10, 30) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (450, 15, 50) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (450, 20, 100) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (450, 40, 150) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (550, 5, 15) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (550, 10, 30) has 1 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (550, 15, 60) has 1 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (550, 20, 100) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (550, 40, 150) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (650, 5, 15) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (650, 10, 30) has 3 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (650, 15, 60) has 6 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (650, 20, 100) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (650, 40, 150) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (750, 5, 15) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (750, 10, 30) has 1 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (750, 15, 60) has 2 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (750, 20, 100) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (750, 40, 240) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (850, 5, 15) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (850, 10, 30) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (850, 15, 60) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (850, 20, 100) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (850, 40, 240) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (1050, 5, 15) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (1050, 10, 30) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (1050, 15, 60) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (1050, 20, 100) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (1050, 40, 240) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (1500, 5, 15) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (1500, 10, 30) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (1500, 15, 60) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (1500, 20, 100) has 0 samples.\n",
      "Sep 10 13:05 <ipython-input-26-9899e7a07d43>[line:40] INFO Train set bucket (1500, 40, 300) has 0 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL DOCS BEFORE BUCKETS:  7\n",
      "TOTAL DOCS BEFORE BUCKETS:  14\n",
      "BATCH SIZE IS:  5\n",
      "BATCHED COUNTER:  14\n",
      "BATCHED LENGTH:  2\n",
      "BATCH SIZE IS:  5\n",
      "BATCHED COUNTER:  7\n",
      "BATCHED LENGTH:  1\n",
      "at the end of epoch: 0\n",
      "Average train loss = 9.21007367, Average perplexity = 9997.33333049\n",
      "Average train acc = 0.00000000\n",
      "validation loss = 9.15196460, perplexity = 9432.95412894\n",
      "Average Validation acc = 0.02950820\n",
      "Time taken to save checkpoint:  3.715604066848755\n",
      "at the end of epoch: 1\n",
      "Average train loss = 9.07603465, Average perplexity = 8743.22726638\n",
      "Average train acc = 0.05921053\n",
      "validation loss = 8.96254662, perplexity = 7805.20907151\n",
      "Average Validation acc = 0.04918033\n",
      "Time taken to save checkpoint:  3.605867624282837\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print (\"In Train\")\n",
    "try:\n",
    "    os.makedirs(FLAGS.train_dir)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "logging.info(\"Preparing summarization data.\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_docid, val_docid, train_queryid, val_queryid, train_sumid, val_sumid = train_test_split(docid, queryid, sumid, test_size=FLAGS.train_test_split, shuffle=False, random_state=42)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto(log_device_placement=False, allow_soft_placement=True)    \n",
    "# please do not use the totality of the GPU memory\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.90\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "with tf.Graph().as_default(), tf.Session(config=config) as sess:\n",
    "    # tensorflow seed must be inside graph\n",
    "    tf.set_random_seed(FLAGS.seed)\n",
    "    np.random.seed(seed=FLAGS.seed)\n",
    "\n",
    "    # Create model.\n",
    "    logging.info(\"Creating %d layers of %d units.\" %\n",
    "                 (FLAGS.num_layers, FLAGS.size))\n",
    "    train_writer = tf.summary.FileWriter(FLAGS.tfboard+'/train', sess.graph)\n",
    "    model = create_model(sess, doc_dict, sum_dict, False)\n",
    "\n",
    "    # Read data into buckets and compute their sizes.\n",
    "    logging.info(\"Create buckets.\")\n",
    "    dev_set = create_bucket(val_docid, val_queryid, val_sumid)\n",
    "    train_set = create_bucket(train_docid, train_queryid, train_sumid)\n",
    "\n",
    "    train_bucket_sizes = [len(train_set[b]) for b in range(len(_buckets))]\n",
    "    train_total_size = float(sum(train_bucket_sizes))\n",
    "    train_buckets_scale = [sum(train_bucket_sizes[:i + 1]) / train_total_size for i in range(len(train_bucket_sizes))]\n",
    "\n",
    "    for (s_size, q_size, t_size), nsample in zip(_buckets, train_bucket_sizes):\n",
    "        logging.info(\"Train set bucket ({}, {}, {}) has {} samples.\".format(\n",
    "            s_size, q_size, t_size, nsample))\n",
    "    batched_train_set = model.batchify(train_set, _buckets, FLAGS.batch_size)\n",
    "    batched_dev_set = model.batchify(dev_set, _buckets, FLAGS.batch_size)\n",
    "    # This is the training loop.\n",
    "    step_time, train_acc, train_loss = 0.0, 0.0, 0.0\n",
    "    step_start_time = 0\n",
    "    num_epoch = 0\n",
    "    step_time = 0\n",
    "    while num_epoch <= FLAGS.max_epochs:\n",
    "        epoch_train_loss = 0.0 \n",
    "        epoch_train_acc = 0.0\n",
    "        current_train_step = 0\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        for batch_train in batched_train_set:\n",
    "            \n",
    "            \n",
    "            step_start_time = time.time()                \n",
    "            encoder_doc_inputs, encoder_query_inputs, decoder_inputs, encoder_doc_len, encoder_query_len, decoder_len = batch_train\n",
    "            \n",
    "            step_train_loss, step_train_acc, _ = model.step(sess, encoder_doc_inputs, encoder_query_inputs, decoder_inputs,\n",
    "                encoder_doc_len, encoder_query_len, decoder_len, False, train_writer)\n",
    "            \n",
    "            step_time = time.time() - step_start_time\n",
    "            #print (\"CURRENT STEP: \", current_train_step, \" STEP TIME: \", step_time)\n",
    "    \n",
    "            step_train_loss =  (step_train_loss * FLAGS.batch_size)/np.sum(decoder_len)\n",
    "            epoch_train_loss += step_train_loss\n",
    "            epoch_train_acc += step_train_acc      \n",
    "            current_train_step += 1\n",
    "            \n",
    "            # Once in a while, we save checkpoint.\n",
    "            if current_train_step % FLAGS.steps_per_checkpoint == 0:\n",
    "                # Save checkpoint and zero timer and loss.\n",
    "                save_time_start = time.time()\n",
    "                checkpoint_path = os.path.join(FLAGS.train_dir, \"model.ckpt\")\n",
    "                model.saver.save(sess, checkpoint_path, global_step=model.global_step)\n",
    "                time_taken_to_save = time.time() - save_time_start\n",
    "                print(\"Time taken to save checkpoint: \", time_taken_to_save)\n",
    "\n",
    "            # Once in a while, we print statistics and run evals.\n",
    "            if current_train_step % FLAGS.steps_per_print == 0:\n",
    "                # Print statistics for the previous epoch.\n",
    "                print (\"Epoch: %d, GlobalStep: %d, step-time %.2f, Acc: %.4f, Loss: %.4f, Perpxty: %.2f\" % (num_epoch, model.global_step.eval(), \n",
    "                                               step_time, \n",
    "                                               step_train_acc, \n",
    "                                               step_train_loss, \n",
    "                                               np.exp(float(step_train_loss))))\n",
    "                step_time, train_acc, train_loss = 0.0, 0.0, 0.0   \n",
    "            \n",
    "            \n",
    "\n",
    "        #epoch_train_loss, epoch_train_acc, current_train_step = 1., 2., 15\n",
    "        epoch_eval_loss, epoch_eval_acc = 0.0, 0.0\n",
    "        current_eval_step = 0\n",
    "        for batch_dev in batched_dev_set:\n",
    "            \n",
    "            encoder_doc_inputs, encoder_query_inputs, decoder_inputs, encoder_doc_len, encoder_query_len, decoder_len = batch_dev\n",
    "            step_eval_loss, step_eval_acc, _ = model.step(sess, encoder_doc_inputs,encoder_query_inputs,\n",
    "                                        decoder_inputs, encoder_doc_len, encoder_query_len,\n",
    "                                        decoder_len, True)\n",
    "            step_eval_loss = (step_eval_loss * FLAGS.batch_size) / np.sum(decoder_len)\n",
    "            epoch_eval_loss += step_eval_loss\n",
    "            epoch_eval_acc += step_eval_acc\n",
    "            current_eval_step += 1\n",
    "                \n",
    "        print(\"at the end of epoch:\", num_epoch)\n",
    "        print(\"Average train loss = %6.8f, Average perplexity = %6.8f\" % (epoch_train_loss/current_train_step, np.exp(epoch_train_loss/current_train_step)))\n",
    "        print(\"Average train acc = %6.8f\" % (epoch_train_acc/current_train_step))\n",
    "        print(\"validation loss = %6.8f, perplexity = %6.8f\" % (epoch_eval_loss/current_eval_step, np.exp(epoch_eval_loss/current_eval_step)))\n",
    "        print(\"Average Validation acc = %6.8f\" % (epoch_eval_acc/current_eval_step))\n",
    "\n",
    "        # Save checkpoint and zero timer and loss.\n",
    "        save_time_start = time.time()\n",
    "        checkpoint_path = os.path.join(FLAGS.train_dir, \"model.ckpt\")\n",
    "        model.saver.save(sess, checkpoint_path, global_step=model.global_step)\n",
    "        time_taken_to_save = time.time() - save_time_start\n",
    "        print(\"Time taken to save checkpoint: \", time_taken_to_save)\n",
    "        num_epoch += 1\n",
    "            \n",
    "    sys.stdout.flush()\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "test_data = (val_docid, val_queryid, val_sumid)\n",
    "\n",
    "with open('test_data.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('test_data.pickle', 'rb') as handle:\n",
    "    loaded_test_data = pickle.load(handle)\n",
    "\n",
    "print (test_data == loaded_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep 10 13:06 <ipython-input-5-680d20c1ecef>[line:2] INFO Try load dict from doc_dict.txt.\n",
      "Sep 10 13:06 <ipython-input-5-680d20c1ecef>[line:16] INFO Load dict doc_dict.txt with 30000 words.\n",
      "Sep 10 13:06 <ipython-input-5-680d20c1ecef>[line:2] INFO Try load dict from sum_dict.txt.\n",
      "Sep 10 13:06 <ipython-input-5-680d20c1ecef>[line:16] INFO Load dict sum_dict.txt with 10000 words.\n",
      "Sep 10 13:06 <ipython-input-28-744382c8e734>[line:29] INFO Creating 1 layers of 400 units.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Decode\n",
      "ENCODER QUERY STATES:  (<tf.Tensor 'seq2seq/encoder_query/Reshape:0' shape=(1, 400) dtype=float32>, <tf.Tensor 'seq2seq/encoder_query/Reshape_1:0' shape=(1, 400) dtype=float32>)\n",
      "ENCODER DOC STATES:  (<tf.Tensor 'seq2seq/encoder_doc/Reshape:0' shape=(1, 400) dtype=float32>, <tf.Tensor 'seq2seq/encoder_doc/Reshape_1:0' shape=(1, 400) dtype=float32>)\n",
      "INIT STATE QUERY:  Tensor(\"seq2seq/decoder/decoder/fully_connected/Relu:0\", shape=(1, 400), dtype=float32)\n",
      "COMBINED FINAL STATES BEFORE:  Tensor(\"seq2seq/decoder/decoder/fully_connected_2/Relu:0\", shape=(1, 400), dtype=float32)\n",
      "COMBINED FINAL STATES:  Tensor(\"seq2seq/decoder/decoder/tile_batch_4/Reshape:0\", shape=(1, 400), dtype=float32)\n",
      "DECODER:  <tensorflow.contrib.seq2seq.python.ops.beam_search_decoder.BeamSearchDecoder object at 0x00000253DB097780>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep 10 13:06 <ipython-input-25-e3aabcbf552f>[line:29] INFO Reading model parameters from model\\model.ckpt-6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Checkpoint:  True\n",
      "INFO:tensorflow:Restoring parameters from model\\model.ckpt-6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep 10 13:06 tf_logging.py[line:115] INFO Restoring parameters from model\\model.ckpt-6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL DOCS BEFORE BUCKETS:  7\n",
      "BATCH SIZE IS:  1\n",
      "BATCHED COUNTER:  7\n",
      "BATCHED LENGTH:  7\n",
      "OUTSIDE STEP:  [6]\n",
      " CAME TO INPUT SHAPE:\n",
      " CAME TO INPUT SHAPE:\n",
      "ENCODER QUERY LEN:  [1]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'qL' with dtype int32 and shape [1]\n\t [[Node: qL = Placeholder[dtype=DT_INT32, shape=[1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: seq2seq/encoder_doc/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/bw/Shape/_169 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_554_s...w/bw/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'qL', defined at:\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-28-744382c8e734>\", line 57, in <module>\n    decode(val_docid, val_queryid, val_sumid)\n  File \"<ipython-input-28-744382c8e734>\", line 31, in decode\n    model = create_model(sess2, doc_dict, sum_dict, True)\n  File \"<ipython-input-25-e3aabcbf552f>\", line 22, in create_model\n    FLAGS.batch_size,     FLAGS.learning_rate,       forward_only, FLAGS.beam_width_size,       dtype=dtype)\n  File \"<ipython-input-23-4c74e0ddda61>\", line 21, in __init__\n    self.encoder_query_len = tf.placeholder(tf.int32, shape=[self.batch_size], name='qL')\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1735, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 5928, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'qL' with dtype int32 and shape [1]\n\t [[Node: qL = Placeholder[dtype=DT_INT32, shape=[1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: seq2seq/encoder_doc/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/bw/Shape/_169 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_554_s...w/bw/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'qL' with dtype int32 and shape [1]\n\t [[Node: qL = Placeholder[dtype=DT_INT32, shape=[1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: seq2seq/encoder_doc/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/bw/Shape/_169 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_554_s...w/bw/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-744382c8e734>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_docid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_queryid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_sumid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"DONE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-744382c8e734>\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(docid, queryid, sumid)\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"OUTSIDE STEP: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_query_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_beam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_doc_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_query_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_doc_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_query_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeam_width_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[1;31m# If there is an EOS symbol in outputs, cut them at that point.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-4c74e0ddda61>\u001b[0m in \u001b[0;36mstep_beam\u001b[1;34m(self, session, encoder_doc_inputs, encoder_query_inputs, encoder_doc_len, encoder_query_len, beam_size)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[0moutput_feed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_feed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1289\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'qL' with dtype int32 and shape [1]\n\t [[Node: qL = Placeholder[dtype=DT_INT32, shape=[1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: seq2seq/encoder_doc/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/bw/Shape/_169 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_554_s...w/bw/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'qL', defined at:\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-28-744382c8e734>\", line 57, in <module>\n    decode(val_docid, val_queryid, val_sumid)\n  File \"<ipython-input-28-744382c8e734>\", line 31, in decode\n    model = create_model(sess2, doc_dict, sum_dict, True)\n  File \"<ipython-input-25-e3aabcbf552f>\", line 22, in create_model\n    FLAGS.batch_size,     FLAGS.learning_rate,       forward_only, FLAGS.beam_width_size,       dtype=dtype)\n  File \"<ipython-input-23-4c74e0ddda61>\", line 21, in __init__\n    self.encoder_query_len = tf.placeholder(tf.int32, shape=[self.batch_size], name='qL')\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1735, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 5928, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"c:\\users\\chudu\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'qL' with dtype int32 and shape [1]\n\t [[Node: qL = Placeholder[dtype=DT_INT32, shape=[1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: seq2seq/encoder_doc/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/bw/Shape/_169 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_554_s...w/bw/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "def batch_iter(docid, queryid, sumid, batch_size, num_epochs):\n",
    "\n",
    "    docid = np.array(docid)\n",
    "    queryid = np.array(queryid)\n",
    "    queryid = np.array(queryid)\n",
    "\n",
    "    num_batches_per_epoch = (len(docid) - 1) // batch_size + 1\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, len(docid))\n",
    "            yield docid[start_index:end_index], queryid[start_index:end_index], sumid[start_index:end_index]\n",
    "\n",
    "def decode(docid, queryid, sumid):\n",
    "    print (\"In Decode\")\n",
    "    FLAGS.load_checkpoint = True\n",
    "    FLAGS.batch_size = 1\n",
    "    # Load vocabularies.\n",
    "    doc_dict = load_dict(FLAGS.doc_dict_path)\n",
    "    sum_dict = load_dict(FLAGS.sum_dict_path)\n",
    "    if doc_dict is None or sum_dict is None:\n",
    "        logging.warning(\"Dict not found.\")   \n",
    "    \n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session() as sess2:\n",
    "        # Create model and load parameters.\n",
    "        logging.info(\"Creating %d layers of %d units.\" %\n",
    "                     (FLAGS.num_layers, FLAGS.size))        \n",
    "        \n",
    "        model = create_model(sess2, doc_dict, sum_dict, True)\n",
    "        \n",
    "        with open('test_data.pickle', 'rb') as handle:\n",
    "            test_data = pickle.load(handle)\n",
    "            docid, queryid, sumid = test_data\n",
    "            dev_set = create_bucket(val_docid, val_queryid, val_sumid)\n",
    "            batched_test_data = model.batchify (dev_set, _buckets, FLAGS.batch_size)\n",
    "\n",
    "        result = []\n",
    "        for batch_test in batched_test_data:\n",
    "\n",
    "            encoder_doc_inputs, encoder_query_inputs, decoder_inputs, encoder_doc_len, encoder_query_len, decoder_len = batch_test\n",
    "            print (\"OUTSIDE STEP: \", encoder_query_len)\n",
    "\n",
    "            outputs = model.step_beam(sess2, encoder_doc_inputs, encoder_query_inputs, encoder_doc_len, encoder_query_len, FLAGS.beam_width_size)\n",
    "\n",
    "            # If there is an EOS symbol in outputs, cut them at that point.\n",
    "            if ID_EOS in outputs:\n",
    "                outputs = outputs[:outputs.index(ID_EOS)]\n",
    "            gen_sum = \" \".join(sen_map2tok(outputs, sum_dict[1]))\n",
    "            result.append(gen_sum)\n",
    "            logging.info(\"Finish {} samples. :: {}\".format(idx, gen_sum[:75]))\n",
    "        with open(FLAGS.test_output, \"w\") as f:\n",
    "            for item in result:\n",
    "                print(item, file=f)\n",
    "\n",
    "decode(val_docid, val_queryid, val_sumid)\n",
    "print (\"DONE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
